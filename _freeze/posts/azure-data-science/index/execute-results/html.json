{
  "hash": "691053dd61a080d86ad83d2faf95edaf",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Getting started with Microsoft Azure for Data Science projects\"\nauthor: \"Colombe Tolokin\"\ndate: \"2025-01-14\"\ncategories: [Azure, Data Science, Cloud]\nimage: \"image.jpg\"\nformat:\n  html:\n    toc: true  \n    toc-depth: 3  \n    toc-location: left  \n---\n\n\n## Introduction\n\nCloud computing has transformed the data science landscape by providing scalable, flexible, and powerful tools to handle large datasets, build complex models, and deploy applications. Microsoft Azure is a leading cloud computing platform that offers a wide range of services for data scientists. From scalable storage to automated machine learning, Azure simplifies the entire data science workflow.\n\nIn this blog, I will guide you step-by-step on how to set up your Azure environment, store data, train a machine learning model, and deploy it for real-world use. Whether you're just getting started or looking to streamline your data science projects, Azure provides all tools to make your workflow more efficient and effective.\n\nHaving used Azure in my role while working with data scientists, I can say it has helped our data workflows and accelerated model deployment in our team projects. Azure's flexibility allowed us to scale infrastructure according to project demands and seamlessly integrate machine learning models into production environments.\n\n## Why choose Azure for Data Science?\n\nAzure stands out as a top cloud platform for data science due to its scalability, integration with popular data science tools, and machine learning services.\n\nScalability and Flexibility: Azure's infrastructure allows you to scale computing resources up or down based on your project's needs. This flexibility ensures that you only pay for what you use, making it cost-efficient for both small experiments and large-scale deployments.\n\nIntegration with Tools: Azure seamlessly integrates with Python, R, Jupyter Notebooks, and other popular data science tools, making it easy for data scientists to transition from local development to cloud-based workflows.\n\nServices: Key Azure services like Azure Machine Learning, Blob Storage, and Databricks simplify complex workflows. Azure also offers tools like Azure Data Factory for pipeline automation and Azure Cognitive Services for AI-driven applications.\n\nLet's start by setting up Azure to begin your data science journey.\n\n## Step 1: Set Up Azure\n\nGetting started with Azure is simple. \nIf you don't already have an Azure account, follow these steps:\n\n### 1. **Sign Up**\n\n- Visit the [Azure Website](https://azure.microsoft.com/en-ca/).  \n  \n![Azure Page](img/start_with_AZURE.png)\n\n- Click on **\"Start Free\"** to begin the sign-up process.\n(Note: Credit card information is required to try the free version of Azure.)\n\n- Sign in with your Microsoft account or create a new one if you don’t have one.  \n    \nAzure’s free account allows you to experiment and build solutions for one month as long as your credits last.\n\n**Learn More:** [Billing and subscription documentation](https://learn.microsoft.com/en-us/azure/cost-management-billing/manage/)\n\n### 2. Install Azure CLI\n\nAzure CLI (Command-Line Interface) is a tool that allows you to manage Azure resources directly from your terminal.\nIt simplifies the process of interacting with Azure services without needing to navigate the web portal.\n\n#### 2.1. **Download and Install Azure CLI**\n\n- Go to the [Azure CLI Installation Page](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli).  \n  \n![Azure CLI Installation](img/azure_cli_install.png)\n\n- Choose the installation option based on your operating system (Windows, macOS, or Linux).  \n- Follow the step-by-step instructions provided on the page.  \n\n#### 2.2. **Verify Installation**\n\nAfter installation, open your terminal and run:\n\n```bash\naz --version\n```\n\nIf the installation was successful, this command will display the installed Azure CLI version.\n\n#### 2.3. **Sign In to Azure**\n\nOnce Azure CLI is installed, sign in to your Azure account:\n\n```bash\naz login\n```\n\nA browser window will open prompting you to log in with your Azure credentials. After logging in, the CLI will display your subscription details. Azure CLI makes it easier to create and manage Azure resources efficiently, saving time and simplifying workflows.\n\n\nWith Azure CLI ready, let's create a Resource Group to organize your project resources. This will help you efficiently manage and group related services, ensuring a smooth and organized workflow throughout your data science project.\n\n## Step 2: Create a Resource Group\n\nA Resource Group in Azure is a container that keeps resources such as storage accounts, virtual machines, and databases. \nIt helps keep your project organized and makes it easier to manage resources.\n\nAlthough you can create a Resource Group using the **Azure CLI**, in this guide, we'll use the **Azure Portal** for a more visual and beginner-friendly experience.\n\n### 2.1. **Create a Resource Group via Azure Portal**\n\n- Go to the [Azure Portal](https://portal.azure.com/).  \n  \n- In the search bar at the top, type **\"Resource Groups\"** and click on it.  \nor\n- Click on the hamburger menu at the top left.\n  \n <img src=\"img/resource_group.png\" alt=\"Resource Groups\" height=\"800\"/>\n\n- Click the **\"+ Create\"** button to start creating a new Resource Group.  \n\n- **Fill in the details:**  \n  - **Subscription:** Select your Azure subscription.  \n  - **Resource Group Name:** Enter a name for your ressource.  \n  - **Region:** Choose a region close to you.  \n  \n- Click **\"Review + Create\"** and then **\"Create\"** to finalize.\n\n### 2.2. **Verify the Resource Group**\n\nOnce the deployment is complete, you’ll be redirected to the Resource Group overview page where you can manage your resources.\n\n- Learn more: [Azure Resource Groups](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/manage-resource-groups-portal)\n\nThe next step is to set up our Azure Storage to manage the project’s data.\n\n## Step 3: Configure Azure Storage\n\nAzure Blob Storage is a solution for storing large files, datasets, and backups. \nIt offers integration with other Azure services, making it an excellent choice for managing unstructured data in data science projects. Its scalability, security, and cost-effectiveness make it ideal for growing projects.\n\n### 3.1. **Create a Storage Account**\n\nA **Storage Account** in Azure allows you to access Blob Storage and other storage services.\n\n- Go to the [Azure Portal](https://portal.azure.com/) if you’re not already signed in.  \n- In the search bar, type **\"Storage Accounts\"** and click on it.  \n- Click on **\"+ Create\"** to start a new storage account.\n\n**Fill in the details:**  \n- **Subscription:** Select your Azure subscription.  \n- **Resource Group:** Choose the Resource Group you created earlier.  \n- **Storage Account Name:** Enter a unique name using lowercase letters only.  \n- **Region:** Select the same region as your Resource Group for better performance.  \n- **Performance:** Keep as **Standard** for general use.  \n- **Redundancy:** Choose **Locally-redundant storage (LRS)** for cost-effective redundancy.\n\n- Click **\"Review + Create\"**, then click **\"Create\"** to deploy the storage account.\n\n**Learn More:** [Create a Storage Account](https://learn.microsoft.com/en-us/azure/storage/common/storage-account-create)\n\n### 3.2. **Upload Data to Blob Storage**\n\nOnce your storage account is ready, you can upload data to Blob Storage.\n\n- In the Azure Portal, go to your **Storage Account**.  \n- Under **Data storage**, click **\"Containers\"**.  \n- Click **\"+ Container\"** to create a new container.\n  - **Name:** Enter a name for your container.  \n  - **Public Access Level:** Set to **Private (no anonymous access)** for security.  \n- Click **\"Create\"**.\n\n### 3.3. **Upload Files:**\n\n- Open the newly created container.  \n- Click **\"Upload\"** to add datasets like `.csv`, `.json`, etc.\n\n**Learn More:** [Upload Files to Blob Storage](https://learn.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-portal)\n\n### 3.4. **Verify the Uploaded Data**\n\nTo confirm that your data was uploaded successfully:\n\n- Go to your container and check the list of uploaded files.  \n- You can download files or review their properties directly in the portal.\n\nAzure Blob Storage ensures your data is secure, scalable, and always accessible for your data science workflows.\n\n**Learn More:** [Azure Blob Storage Overview](https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blobs-overview)\n\n\n## Step 4: Train a Machine Learning Model with Azure AutoML\n\nAzure AutoML makes it easier to create machine learning models by automating model selection and tuning.\nIn htis step we will learn how to set up AutoML for training a tabular data. Although there are two ways of achiveing this. We will opt for the Azure CLI option. Run the following codes to set up on your machine.\n\nThe following are required a subscription, a resource group and a workspace.\n\nWe will be using the \n\n\n```{bash}\naz login\n```\n\n\n\n\n\nLearn more about AutoML: [Azure AutoML Documentation](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train)\n\n## Step 5: Deploy the Model\n\nOnce the model is trained, it can be deployed as a web service for real-time predictions.\n\n```python\nfrom azureml.core.model import InferenceConfig, Model\nfrom azureml.core.webservice import AciWebservice\n\n# Register the model\nmodel = run.register_model(model_name='best_model', model_path='outputs/model.pkl')\n\n# Define inference configuration\ninference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n\ndeployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n\n# Deploy the model\nservice = Model.deploy(\n    workspace=ws,\n    name=\"model-service\",\n    models=[model],\n    inference_config=inference_config,\n    deployment_config=deployment_config\n)\nservice.wait_for_deployment(show_output=True)\n\nprint(f\"Scoring URI: {service.scoring_uri}\")\n```\n\nLearn more: [Deploy Models with Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where)\n\n## Best Practices\n\n- **Resource Management:** Use Azure Cost Management tools to track spending.\n- **Data Security:** Use encryption and role-based access control (RBAC) to protect data.\n- **Scaling:** Use Azure Kubernetes Service (AKS) for scalable deployments.\n- **Automation:** Implement CI/CD pipelines with Azure DevOps for model updates.\n\n## Conclusion\n\nMicrosoft Azure is a powerful tool for building, training, and deploying machine learning models. Its scalable and flexible services make it ideal for data science projects. By following this guide, you can efficiently manage your data science workflow, from data storage to deploying models for real-world use.\n\n## References\n\n1. **Azure Free Account:** [https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/)  \n2. **Azure CLI Documentation:** [https://docs.microsoft.com/en-us/cli/azure/install-azure-cli](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli)  \n3. **Azure Blob Storage:** [https://learn.microsoft.com/en-us/azure/storage/blobs/](https://learn.microsoft.com/en-us/azure/storage/blobs/)  \n4. **Azure Machine Learning Documentation:** [https://learn.microsoft.com/en-us/azure/machine-learning/](https://learn.microsoft.com/en-us/azure/machine-learning/)  \n5. **Azure AutoML Documentation:** [https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train)  \n6. **Deploy Models with Azure ML:** [https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where) \n7. **Azure in the Context of Data Science**[https://www.spyglassmtg.com/blog/azure-in-the-context-of-data-science](https://www.spyglassmtg.com/blog/azure-in-the-context-of-data-science) \n8. **TODO**[https://learn.microsoft.com/en-ca/azure/machine-learning/prompt-flow/overview-what-is-prompt-flow?view=azureml-api-2](https://learn.microsoft.com/en-ca/azure/machine-learning/prompt-flow/overview-what-is-prompt-flow?view=azureml-api-2)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}